{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e31a571-4086-40a7-8aad-749cd00efa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Crawled: http://localhost:8080\n",
      "✅ Crawled: http://localhost:8080/instructions.php\n",
      "✅ Crawled: http://localhost:8080/setup.php\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/brute\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/exec\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/csrf\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/fi/?page=include.php\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/upload\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/captcha\n",
      "✅ Crawled: http://localhost:8080/vulnerabilities/sqli\n",
      "\n",
      "=== Pages Crawled ===\n",
      "http://localhost:8080\n",
      "http://localhost:8080/instructions.php\n",
      "http://localhost:8080/setup.php\n",
      "http://localhost:8080/vulnerabilities/brute\n",
      "http://localhost:8080/vulnerabilities/exec\n",
      "http://localhost:8080/vulnerabilities/csrf\n",
      "http://localhost:8080/vulnerabilities/fi/?page=include.php\n",
      "http://localhost:8080/vulnerabilities/upload\n",
      "http://localhost:8080/vulnerabilities/captcha\n",
      "http://localhost:8080/vulnerabilities/sqli\n",
      "\n",
      "=== Forms Found ===\n",
      "\n",
      "URL: http://localhost:8080/setup.php\n",
      "{'method': 'post', 'action': 'http://localhost:8080/setup.php', 'inputs': [{'name': 'create_db', 'type': 'submit', 'value': 'Create / Reset Database'}, {'name': 'user_token', 'type': 'hidden', 'value': '4fc46adb7a696732afab28a6d8575a9a'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/brute\n",
      "{'method': 'get', 'action': 'http://localhost:8080/vulnerabilities/brute', 'inputs': [{'name': 'username', 'type': 'text', 'value': ''}, {'name': 'password', 'type': 'password', 'value': ''}, {'name': 'Login', 'type': 'submit', 'value': 'Login'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/exec\n",
      "{'method': 'post', 'action': 'http://localhost:8080/vulnerabilities/exec', 'inputs': [{'name': 'ip', 'type': 'text', 'value': ''}, {'name': 'Submit', 'type': 'submit', 'value': 'Submit'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/csrf\n",
      "{'method': 'get', 'action': 'http://localhost:8080/vulnerabilities/csrf', 'inputs': [{'name': 'password_new', 'type': 'password', 'value': ''}, {'name': 'password_conf', 'type': 'password', 'value': ''}, {'name': 'Change', 'type': 'submit', 'value': 'Change'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/upload\n",
      "{'method': 'post', 'action': 'http://localhost:8080/vulnerabilities/upload', 'inputs': [{'name': 'MAX_FILE_SIZE', 'type': 'hidden', 'value': '100000'}, {'name': 'uploaded', 'type': 'file', 'value': ''}, {'name': 'Upload', 'type': 'submit', 'value': 'Upload'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/captcha\n",
      "{'method': 'post', 'action': 'http://localhost:8080/vulnerabilities/captcha', 'inputs': [{'name': 'step', 'type': 'hidden', 'value': '1'}, {'name': 'password_new', 'type': 'password', 'value': ''}, {'name': 'password_conf', 'type': 'password', 'value': ''}, {'name': 'Change', 'type': 'submit', 'value': 'Change'}]}\n",
      "\n",
      "URL: http://localhost:8080/vulnerabilities/sqli\n",
      "{'method': 'get', 'action': 'http://localhost:8080/vulnerabilities/sqli', 'inputs': [{'name': 'id', 'type': 'text', 'value': ''}, {'name': 'Submit', 'type': 'submit', 'value': 'Submit'}]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from urllib.parse import urljoin, urldefrag\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class DVWACrawler:\n",
    "    def __init__(self, base_url, username=\"admin\", password=\"password\", max_pages=20, delay=1):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.max_pages = max_pages\n",
    "        self.delay = delay\n",
    "        self.session = requests.Session()\n",
    "        self.visited = set()\n",
    "        self.queue = [self.base_url]\n",
    "        self.pages = {}\n",
    "        self.forms = {}\n",
    "\n",
    "        self.login(username, password)\n",
    "\n",
    "    def login(self, username, password):\n",
    "        \"\"\"Logs into DVWA using session-based authentication.\"\"\"\n",
    "        login_url = f\"{self.base_url}/login.php\"\n",
    "        resp = self.session.get(login_url)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        token = soup.find(\"input\", {\"name\": \"user_token\"})\n",
    "        token_val = token[\"value\"] if token else \"\"\n",
    "\n",
    "        payload = {\n",
    "            \"username\": username,\n",
    "            \"password\": password,\n",
    "            \"Login\": \"Login\",\n",
    "            \"user_token\": token_val\n",
    "        }\n",
    "\n",
    "        self.session.post(login_url, data=payload)\n",
    "\n",
    "    def extract_links(self, html, page_url):\n",
    "        \"\"\"Extracts all same-domain links from a page.\"\"\"\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        links = []\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            abs_url = urljoin(page_url, a[\"href\"])\n",
    "            clean_url = urldefrag(abs_url)[0].rstrip(\"/\")\n",
    "            if clean_url.startswith(self.base_url):\n",
    "                links.append(clean_url)\n",
    "        return links\n",
    "\n",
    "    def extract_forms(self, html, page_url):\n",
    "        \"\"\"Extracts form details (method, action, inputs).\"\"\"\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        forms = []\n",
    "        for form in soup.find_all(\"form\"):\n",
    "            details = {\n",
    "                \"method\": form.get(\"method\", \"get\").lower(),\n",
    "                \"action\": urljoin(page_url, form.get(\"action\", \"\")),\n",
    "                \"inputs\": []\n",
    "            }\n",
    "            for inp in form.find_all(\"input\"):\n",
    "                details[\"inputs\"].append({\n",
    "                    \"name\": inp.get(\"name\"),\n",
    "                    \"type\": inp.get(\"type\", \"text\"),\n",
    "                    \"value\": inp.get(\"value\", \"\")\n",
    "                })\n",
    "            forms.append(details)\n",
    "        return forms\n",
    "\n",
    "    def crawl(self):\n",
    "        \"\"\"Main crawl loop.\"\"\"\n",
    "        while self.queue and len(self.visited) < self.max_pages:\n",
    "            url = self.queue.pop(0).rstrip(\"/\")\n",
    "            if url in self.visited:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                resp = self.session.get(url, timeout=10)\n",
    "                html = resp.text\n",
    "            except Exception as e:\n",
    "                print(f\" Error fetching {url}: {e}\")\n",
    "                self.visited.add(url)\n",
    "                continue\n",
    "\n",
    "            self.pages[url] = html\n",
    "\n",
    "            forms = self.extract_forms(html, url)\n",
    "            if forms:\n",
    "                self.forms[url] = forms\n",
    "\n",
    "            for link in self.extract_links(html, url):\n",
    "                if link not in self.visited and link not in self.queue:\n",
    "                    self.queue.append(link)\n",
    "\n",
    "            self.visited.add(url)\n",
    "\n",
    "            print(f\"✅ Crawled: {url}\")\n",
    "\n",
    "            time.sleep(self.delay)\n",
    "\n",
    "        return {\"pages\": self.pages, \"forms\": self.forms}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"http://localhost:8080\"  \n",
    "    crawler = DVWACrawler(base_url, username=\"admin\", password=\"password\", max_pages=10, delay=1)\n",
    "    results = crawler.crawl()\n",
    "\n",
    "    print(\"\\n=== Pages Crawled ===\")\n",
    "    for url in results[\"pages\"].keys():\n",
    "        print(url)\n",
    "\n",
    "    print(\"\\n=== Forms Found ===\")\n",
    "    for url, forms in results[\"forms\"].items():\n",
    "        print(f\"\\nURL: {url}\")\n",
    "        for f in forms:\n",
    "            print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6289ce-c32f-45de-bde5-3b86b6d33cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
